{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Machine Learning Demos There are so many web demos for machine learning tasks Are you prototyping some weird idea? need to try out several models in your pipeline? Don't have the hardware to run some crucial component? This repo using requests to hit several endpoints for a lot of web apis, try something new in your pipeline before investing time on your own implementation and setup! Please do not abuse this, it is meant for quick prototyping and experimentation only! Have a suggestion for another web demo? open an issue Found something broken? open an issue Is your demo here and you want it taken down? open an issue or send me an email jarbasai@mailfence.com supported demos allen","title":"Home"},{"location":"#machine-learning-demos","text":"There are so many web demos for machine learning tasks Are you prototyping some weird idea? need to try out several models in your pipeline? Don't have the hardware to run some crucial component? This repo using requests to hit several endpoints for a lot of web apis, try something new in your pipeline before investing time on your own implementation and setup! Please do not abuse this, it is meant for quick prototyping and experimentation only! Have a suggestion for another web demo? open an issue Found something broken? open an issue Is your demo here and you want it taken down? open an issue or send me an email jarbasai@mailfence.com","title":"Machine Learning Demos"},{"location":"#supported-demos","text":"allen","title":"supported demos"},{"location":"ai_demos.allenai/","text":"Module ai_demos.allenai NER def NER(text) aristo def aristo(text) NOTES: DO NOT ABUSE use the source https://github.com/allenai/aristo-mini constituency_parse def constituency_parse(sentence) A constituency parse tree breaks a text into sub-phrases, or constituents. Non-terminals in the tree are types of phrases, the terminals are the words in the sentence. This demo is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans described in Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples (Joshi et al, 2018). This model uses ELMo embeddings, which are completely character based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction. :param sentence: :return: euclid def euclid(text) NOTES: DO NOT ABUSE machine_comprehension def machine_comprehension(question, passage) Machine Comprehension (MC) answers natural language questions by selecting an answer span within an evidence text. The AllenNLP toolkit provides the following MC visualization, which can be used for any MC model in AllenNLP. This page demonstrates a reimplementation of BiDAF (Seo et al, 2017), or Bi-Directional Attention Flow, a widely used MC baseline that achieved state-of-the-art accuracies on the SQuAD dataset (Wikipedia sentences) in early 2017. :param question: :param passage: :return: semantic_role_labeling def semantic_role_labeling(sentence) Semantic Role Labeling (SRL) recovers the latent predicate argument structure of a sentence, providing representations that answer basic questions about sentence meaning, including \u201cwho\u201d did \u201cwhat\u201d to \u201cwhom,\u201d etc. The AllenNLP toolkit provides the following SRL visualization, which can be used for any SRL model in AllenNLP. This page demonstrates a reimplementation of a deep BiLSTM model (He et al, 2017), which is currently state of the art for PropBank SRL (Newswire sentences). :param sentence: :return: textual_entailment def textual_entailment(premise, hypothesis) Textual Entailment (TE) takes a pair of sentences and predicts whether the facts in the first necessarily imply the facts in the second one. The AllenNLP toolkit provides the following TE visualization, which can be run for any TE model you develop. This page demonstrates a reimplementation of the decomposable attention model (Parikh et al, 2017) , which was state of the art for the SNLI benchmark (short sentences about visual scenes) in 2016. Rather than pre-trained Glove vectors, this model uses ELMo embeddings, which are completely character based and improve performance by 2% :param premise: :param hypotheses: :return:","title":"allenai"},{"location":"ai_demos.allenai/#module-ai_demosallenai","text":"","title":"Module ai_demos.allenai"},{"location":"ai_demos.allenai/#ner","text":"def NER(text)","title":"NER"},{"location":"ai_demos.allenai/#aristo","text":"def aristo(text) NOTES: DO NOT ABUSE use the source https://github.com/allenai/aristo-mini","title":"aristo"},{"location":"ai_demos.allenai/#constituency95parse","text":"def constituency_parse(sentence) A constituency parse tree breaks a text into sub-phrases, or constituents. Non-terminals in the tree are types of phrases, the terminals are the words in the sentence. This demo is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans described in Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples (Joshi et al, 2018). This model uses ELMo embeddings, which are completely character based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction. :param sentence: :return:","title":"constituency_parse"},{"location":"ai_demos.allenai/#euclid","text":"def euclid(text) NOTES: DO NOT ABUSE","title":"euclid"},{"location":"ai_demos.allenai/#machine95comprehension","text":"def machine_comprehension(question, passage) Machine Comprehension (MC) answers natural language questions by selecting an answer span within an evidence text. The AllenNLP toolkit provides the following MC visualization, which can be used for any MC model in AllenNLP. This page demonstrates a reimplementation of BiDAF (Seo et al, 2017), or Bi-Directional Attention Flow, a widely used MC baseline that achieved state-of-the-art accuracies on the SQuAD dataset (Wikipedia sentences) in early 2017. :param question: :param passage: :return:","title":"machine_comprehension"},{"location":"ai_demos.allenai/#semantic95role95labeling","text":"def semantic_role_labeling(sentence) Semantic Role Labeling (SRL) recovers the latent predicate argument structure of a sentence, providing representations that answer basic questions about sentence meaning, including \u201cwho\u201d did \u201cwhat\u201d to \u201cwhom,\u201d etc. The AllenNLP toolkit provides the following SRL visualization, which can be used for any SRL model in AllenNLP. This page demonstrates a reimplementation of a deep BiLSTM model (He et al, 2017), which is currently state of the art for PropBank SRL (Newswire sentences). :param sentence: :return:","title":"semantic_role_labeling"},{"location":"ai_demos.allenai/#textual95entailment","text":"def textual_entailment(premise, hypothesis) Textual Entailment (TE) takes a pair of sentences and predicts whether the facts in the first necessarily imply the facts in the second one. The AllenNLP toolkit provides the following TE visualization, which can be run for any TE model you develop. This page demonstrates a reimplementation of the decomposable attention model (Parikh et al, 2017) , which was state of the art for the SNLI benchmark (short sentences about visual scenes) in 2016. Rather than pre-trained Glove vectors, this model uses ELMo embeddings, which are completely character based and improve performance by 2% :param premise: :param hypotheses: :return:","title":"textual_entailment"},{"location":"ai_demos.argumentext/","text":"Module ai_demos.argumentext get_arguments def get_arguments(text)","title":"argumentext"},{"location":"ai_demos.argumentext/#module-ai_demosargumentext","text":"","title":"Module ai_demos.argumentext"},{"location":"ai_demos.argumentext/#get95arguments","text":"def get_arguments(text)","title":"get_arguments"},{"location":"ai_demos.cogcomp/","text":"Module ai_demos.cogcomp coreference def coreference(text)","title":"cogcomp"},{"location":"ai_demos.cogcomp/#module-ai_demoscogcomp","text":"","title":"Module ai_demos.cogcomp"},{"location":"ai_demos.cogcomp/#coreference","text":"def coreference(text)","title":"coreference"},{"location":"ai_demos.cornell/","text":"Module ai_demos.cornell politeness def politeness(text)","title":"cornell"},{"location":"ai_demos.cornell/#module-ai_demoscornell","text":"","title":"Module ai_demos.cornell"},{"location":"ai_demos.cornell/#politeness","text":"def politeness(text)","title":"politeness"},{"location":"ai_demos.deepai/","text":"Module ai_demos.deepai deepmask def deepmask(picture, save_path=None) demographic_recognition def demographic_recognition(face_picture) densecap def densecap(picture) image_similarity def image_similarity(picture1, picture2) neuraltalk def neuraltalk(picture) nudity_detection def nudity_detection(picture)","title":"deepai"},{"location":"ai_demos.deepai/#module-ai_demosdeepai","text":"","title":"Module ai_demos.deepai"},{"location":"ai_demos.deepai/#deepmask","text":"def deepmask(picture, save_path=None)","title":"deepmask"},{"location":"ai_demos.deepai/#demographic95recognition","text":"def demographic_recognition(face_picture)","title":"demographic_recognition"},{"location":"ai_demos.deepai/#densecap","text":"def densecap(picture)","title":"densecap"},{"location":"ai_demos.deepai/#image95similarity","text":"def image_similarity(picture1, picture2)","title":"image_similarity"},{"location":"ai_demos.deepai/#neuraltalk","text":"def neuraltalk(picture)","title":"neuraltalk"},{"location":"ai_demos.deepai/#nudity95detection","text":"def nudity_detection(picture)","title":"nudity_detection"},{"location":"ai_demos.deepface/","text":"Module ai_demos.deepface face_analysis def face_analysis(face_picture) face_emotion def face_emotion(face_picture)","title":"deepface"},{"location":"ai_demos.deepface/#module-ai_demosdeepface","text":"","title":"Module ai_demos.deepface"},{"location":"ai_demos.deepface/#face95analysis","text":"def face_analysis(face_picture)","title":"face_analysis"},{"location":"ai_demos.deepface/#face95emotion","text":"def face_emotion(face_picture)","title":"face_emotion"},{"location":"ai_demos.deepmoji/","text":"Module ai_demos.deepmoji emojis def emojis(text)","title":"deepmoji"},{"location":"ai_demos.deepmoji/#module-ai_demosdeepmoji","text":"","title":"Module ai_demos.deepmoji"},{"location":"ai_demos.deepmoji/#emojis","text":"def emojis(text)","title":"emojis"},{"location":"ai_demos.deepwarp/","text":"Module ai_demos.deepwarp animate_eyes def animate_eyes(face_picture, mode=None, engine='deepwarp_demo') cross_eyes def cross_eyes(face_picture) roll_eyes def roll_eyes(face_picture) scroll_eyes def scroll_eyes(face_picture) shift_eyes def shift_eyes(face_picture)","title":"deepwarp"},{"location":"ai_demos.deepwarp/#module-ai_demosdeepwarp","text":"","title":"Module ai_demos.deepwarp"},{"location":"ai_demos.deepwarp/#animate95eyes","text":"def animate_eyes(face_picture, mode=None, engine='deepwarp_demo')","title":"animate_eyes"},{"location":"ai_demos.deepwarp/#cross95eyes","text":"def cross_eyes(face_picture)","title":"cross_eyes"},{"location":"ai_demos.deepwarp/#roll95eyes","text":"def roll_eyes(face_picture)","title":"roll_eyes"},{"location":"ai_demos.deepwarp/#scroll95eyes","text":"def scroll_eyes(face_picture)","title":"scroll_eyes"},{"location":"ai_demos.deepwarp/#shift95eyes","text":"def shift_eyes(face_picture)","title":"shift_eyes"},{"location":"ai_demos.haystackai/","text":"Module ai_demos.haystackai age def age(picture_path) analyze def analyze(picture_path, engine='haystackai_demo') emotion def emotion(picture_path) ethnicity def ethnicity(picture_path) flower_demo def flower_demo(picture_path) gender def gender(picture_path) hotness def hotness(picture_path) inception def inception(picture_path) nudity def nudity(picture_path) open_nsfw def open_nsfw(picture_path, engine='haystackai_demo') NOTES: self hosted https://github.com/itoolset/nsfw places def places(picture_path) yearbook_demo def yearbook_demo(picture_path)","title":"haystackai"},{"location":"ai_demos.haystackai/#module-ai_demoshaystackai","text":"","title":"Module ai_demos.haystackai"},{"location":"ai_demos.haystackai/#age","text":"def age(picture_path)","title":"age"},{"location":"ai_demos.haystackai/#analyze","text":"def analyze(picture_path, engine='haystackai_demo')","title":"analyze"},{"location":"ai_demos.haystackai/#emotion","text":"def emotion(picture_path)","title":"emotion"},{"location":"ai_demos.haystackai/#ethnicity","text":"def ethnicity(picture_path)","title":"ethnicity"},{"location":"ai_demos.haystackai/#flower95demo","text":"def flower_demo(picture_path)","title":"flower_demo"},{"location":"ai_demos.haystackai/#gender","text":"def gender(picture_path)","title":"gender"},{"location":"ai_demos.haystackai/#hotness","text":"def hotness(picture_path)","title":"hotness"},{"location":"ai_demos.haystackai/#inception","text":"def inception(picture_path)","title":"inception"},{"location":"ai_demos.haystackai/#nudity","text":"def nudity(picture_path)","title":"nudity"},{"location":"ai_demos.haystackai/#open95nsfw","text":"def open_nsfw(picture_path, engine='haystackai_demo') NOTES: self hosted https://github.com/itoolset/nsfw","title":"open_nsfw"},{"location":"ai_demos.haystackai/#places","text":"def places(picture_path)","title":"places"},{"location":"ai_demos.haystackai/#yearbook95demo","text":"def yearbook_demo(picture_path)","title":"yearbook_demo"},{"location":"ai_demos.huggingface/","text":"Module ai_demos.huggingface neuralconvo def neuralconvo(text) This is a demo of chatting with a Deep learning chatbot trained through Neuralconvo, a Torch library that implements Sequence to Sequence Learning with Neural Networks (seq2seq), reproducing the results in the Neural Conversational Model paper (aka the Google chatbot). source: http://neuralconvo.huggingface.co/ :param text: (str) utterance to send to bot :return: (str) text response from bot neuralcoref def neuralcoref(text) Coreference is the fact that two or more expressions in a text \u2013 like pronouns or nouns \u2013 link to the same person or thing. It is a classical Natural language processing task, that has seen a revival of interest in the past two years as several research groups applied cutting-edge deep-learning and reinforcement-learning techniques to it. It is also one of the key building blocks to building conversational Artificial intelligences. I source: https://huggingface.co/coref/ :param text: (str) your sentence :return: (dict) json response","title":"huggingface"},{"location":"ai_demos.huggingface/#module-ai_demoshuggingface","text":"","title":"Module ai_demos.huggingface"},{"location":"ai_demos.huggingface/#neuralconvo","text":"def neuralconvo(text) This is a demo of chatting with a Deep learning chatbot trained through Neuralconvo, a Torch library that implements Sequence to Sequence Learning with Neural Networks (seq2seq), reproducing the results in the Neural Conversational Model paper (aka the Google chatbot). source: http://neuralconvo.huggingface.co/ :param text: (str) utterance to send to bot :return: (str) text response from bot","title":"neuralconvo"},{"location":"ai_demos.huggingface/#neuralcoref","text":"def neuralcoref(text) Coreference is the fact that two or more expressions in a text \u2013 like pronouns or nouns \u2013 link to the same person or thing. It is a classical Natural language processing task, that has seen a revival of interest in the past two years as several research groups applied cutting-edge deep-learning and reinforcement-learning techniques to it. It is also one of the key building blocks to building conversational Artificial intelligences. I source: https://huggingface.co/coref/ :param text: (str) your sentence :return: (dict) json response","title":"neuralcoref"},{"location":"ai_demos.lrp/","text":"Module ai_demos.lrp vqa def vqa(picture, question)","title":"lrp"},{"location":"ai_demos.lrp/#module-ai_demoslrp","text":"","title":"Module ai_demos.lrp"},{"location":"ai_demos.lrp/#vqa","text":"def vqa(picture, question)","title":"vqa"},{"location":"ai_demos.polyglot/","text":"Module ai_demos.polyglot NER def NER(text)","title":"polyglot"},{"location":"ai_demos.polyglot/#module-ai_demospolyglot","text":"","title":"Module ai_demos.polyglot"},{"location":"ai_demos.polyglot/#ner","text":"def NER(text)","title":"NER"},{"location":"ai_demos.pornstarbyface/","text":"Module ai_demos.pornstarbyface pornstar_match def pornstar_match(face_picture)","title":"pornstarbyface"},{"location":"ai_demos.pornstarbyface/#module-ai_demospornstarbyface","text":"","title":"Module ai_demos.pornstarbyface"},{"location":"ai_demos.pornstarbyface/#pornstar95match","text":"def pornstar_match(face_picture)","title":"pornstar_match"},{"location":"ai_demos.semanticparsing/","text":"Module ai_demos.semanticparsing relation_extraction def relation_extraction(text)","title":"semanticparsing"},{"location":"ai_demos.semanticparsing/#module-ai_demossemanticparsing","text":"","title":"Module ai_demos.semanticparsing"},{"location":"ai_demos.semanticparsing/#relation95extraction","text":"def relation_extraction(text)","title":"relation_extraction"},{"location":"ai_demos.sense2vec/","text":"Module ai_demos.sense2vec similar def similar(text, sense='auto')","title":"sense2vec"},{"location":"ai_demos.sense2vec/#module-ai_demossense2vec","text":"","title":"Module ai_demos.sense2vec"},{"location":"ai_demos.sense2vec/#similar","text":"def similar(text, sense='auto')","title":"similar"},{"location":"ai_demos.sequel/","text":"Module ai_demos.sequel vqa def vqa(picture, question)","title":"sequel"},{"location":"ai_demos.sequel/#module-ai_demossequel","text":"","title":"Module ai_demos.sequel"},{"location":"ai_demos.sequel/#vqa","text":"def vqa(picture, question)","title":"vqa"},{"location":"ai_demos.spacy/","text":"Module ai_demos.spacy NER def NER(text)","title":"spacy"},{"location":"ai_demos.spacy/#module-ai_demosspacy","text":"","title":"Module ai_demos.spacy"},{"location":"ai_demos.spacy/#ner","text":"def NER(text)","title":"NER"},{"location":"ai_demos.textgain/","text":"Module ai_demos.textgain NER def NER(text) age_detect def age_detect(text) gender_detect def gender_detect(text) language_detect def language_detect(text) sentiment def sentiment(text)","title":"textgain"},{"location":"ai_demos.textgain/#module-ai_demostextgain","text":"","title":"Module ai_demos.textgain"},{"location":"ai_demos.textgain/#ner","text":"def NER(text)","title":"NER"},{"location":"ai_demos.textgain/#age95detect","text":"def age_detect(text)","title":"age_detect"},{"location":"ai_demos.textgain/#gender95detect","text":"def gender_detect(text)","title":"gender_detect"},{"location":"ai_demos.textgain/#language95detect","text":"def language_detect(text)","title":"language_detect"},{"location":"ai_demos.textgain/#sentiment","text":"def sentiment(text)","title":"sentiment"},{"location":"ai_demos.turknlp/","text":"Module ai_demos.turknlp similar def similar(text, n=10, model='Finnish 4B wordforms skipgram')","title":"turknlp"},{"location":"ai_demos.turknlp/#module-ai_demosturknlp","text":"","title":"Module ai_demos.turknlp"},{"location":"ai_demos.turknlp/#similar","text":"def similar(text, n=10, model='Finnish 4B wordforms skipgram')","title":"similar"}]}